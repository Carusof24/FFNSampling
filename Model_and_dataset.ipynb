{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMv2Sp+6sKU8d2J7Ma2nX0X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Carusof24/FFNSampling/blob/main/Model_and_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feedfoward\n",
        "\n",
        "Viene definita una rete neurale feedforward con tre layer completamente connessi, usando funzioni di attivazione ReLU nei layer nascosti e Sigmoid nell’output.\n"
      ],
      "metadata": {
        "id": "cZ5JuZr8-EZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Default precision\n",
        "torch.set_default_dtype(torch.float64)\n",
        "\n",
        "# -------------------- #\n",
        "# Feedforward NN Model #\n",
        "# -------------------- #\n",
        "class FeedforwardNet(nn.Module):\n",
        "    def __init__(self, input_dim=100, hidden_dim=100, output_dim=10):\n",
        "        super(FeedforwardNet, self).__init__()\n",
        "        # First hidden layer\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        # Secondo hidden layer\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        # Layer di output\n",
        "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
        "        #these are fully connected layers\n",
        "        # Activaction function\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)   # Attivazione ReLU sul primo hidden layer\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)   # Attivazione ReLU\n",
        "        x = self.fc3(x)\n",
        "        x = self.sigmoid(x)  # Sigmoid per l'output\n",
        "        return x\n",
        "\n",
        "#wrapper is a class that encapsulates another class\n",
        "# NNModel, this class provides a wrapper around the FFN class to manage its weights\n",
        "class NNModel():\n",
        "    def __init__(self, NN, device='cpu', f=None):\n",
        "        self.NN = NN\n",
        "        self.device = device if ('cuda' in device) and torch.cuda.is_available() else 'cpu'\n",
        "        if f:\n",
        "            self.load(f)\n",
        "        else:\n",
        "            self._to_device()\n",
        "            self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        self.weights = {name: param for name, param in self.NN.named_parameters() if param.requires_grad}\n",
        "\n",
        "    def copy(self, grad=False):\n",
        "        if not grad:\n",
        "            wcopy = {name: self.weights[name].detach().clone() for name in self.weights}\n",
        "        else:\n",
        "            wcopy = {name: self.weights[name].grad.detach().clone() for name in self.weights}\n",
        "        return wcopy\n",
        "\n",
        "    def set_weights(self, wnew):\n",
        "        assert all(name in self.weights for name in wnew), f\"NNModel.set_weights(): invalid layer found in wnew. Allowed values: {list(self.weights.keys())}\"\n",
        "        for name, new_param in wnew.items():\n",
        "            for pname, param in self.NN.named_parameters():\n",
        "                if pname == name:\n",
        "                    param.data = new_param.detach().clone()\n",
        "        self._init_weights()\n",
        "\n",
        "    def load(self, f):\n",
        "        with open(f, 'rb') as ptf:\n",
        "            self.NN.load_state_dict(torch.load(ptf, map_location=torch.device(self.device)))\n",
        "        self._to_device()\n",
        "        self._init_weights()\n",
        "\n",
        "    def save(self, f):\n",
        "        with open(f, 'wb') as ptf:\n",
        "            torch.save(self.NN.state_dict(), ptf)\n",
        "\n",
        "    def _to_device(self):\n",
        "        if 'cuda' in self.device:\n",
        "            self.NN.to(self.device)"
      ],
      "metadata": {
        "id": "S0teTesMBej2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Creiamo un dizionario dei pesi della rete, e specificamente i pesi del primo layer (fc1.weight) vengono sostituiti con valori casuali generati da una distribuzione normale.\n",
        "#I pesi modificati vengono quindi reinseriti nel modello tramite il metodo set_weights.\n",
        "#Il codice assicura che i pesi aggiornati nel modello corrispondano a quelli salvati nel wrapper NNModel.\n",
        "#si verifica che i pesi attuali della rete coincidano con quelli memorizzati nel dizionario dei pesi.\n",
        "#La verifica è effettuata confrontando i pesi presenti nel modello e quelli nel dizionario dopo il reset.\n",
        "#il codice dimostra come gestire la modifica, il salvataggio e il ripristino dei pesi in una rete neurale implementata\n",
        "# # Feedfoward\n",
        "\n",
        "# Default precision\n",
        "torch.set_default_dtype(torch.float64)\n",
        "\n",
        "# parameters:\n",
        "input_dim = 100\n",
        "hidden_dim = 100\n",
        "output_dim = 10\n",
        "\n",
        "# Initialize the neural network\n",
        "net = FeedforwardNet(input_dim, hidden_dim, output_dim)\n",
        "model = NNModel(net)\n",
        "\n",
        "\n",
        "# Get the initial weights\n",
        "initial_weights = model.copy()\n",
        "\n",
        "\n",
        "# Modify the weights\n",
        "modified_weights = model.copy()\n",
        "\n",
        "# change the weight of the first layer\n",
        "for name, param in modified_weights.items():\n",
        "    if name == 'fc1.weight':\n",
        "        param.data = torch.randn_like(param.data)\n",
        "        break\n",
        "\n",
        "\n",
        "# Set the modified weights back into the model\n",
        "model.set_weights(modified_weights)\n",
        "\n",
        "\n",
        "# Verify that the weights in the NN and the weights stored in model.weights are the same\n",
        "for name, param in model.NN.named_parameters():\n",
        "    if name in modified_weights:\n",
        "      print(f\"Layer: {name}\")\n",
        "      print(\"Difference between model.weights and NN parameters:\", torch.equal(model.weights[name], param.data))\n",
        "\n",
        "# Reset weights to initial values (example)\n",
        "model.set_weights(initial_weights)\n",
        "\n",
        "# Verify that the weights have been reset correctly\n",
        "for name, param in model.NN.named_parameters():\n",
        "    if name in initial_weights:\n",
        "      print(f\"Layer: {name}\")\n",
        "      print(\"Difference between model.weights and NN parameters after reset:\", torch.equal(model.weights[name], param.data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbKdk-f1WIT7",
        "outputId": "6ec0bf35-7ab3-4aa3-a975-18830d145a0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: fc1.weight\n",
            "Difference between model.weights and NN parameters: True\n",
            "Layer: fc1.bias\n",
            "Difference between model.weights and NN parameters: True\n",
            "Layer: fc2.weight\n",
            "Difference between model.weights and NN parameters: True\n",
            "Layer: fc2.bias\n",
            "Difference between model.weights and NN parameters: True\n",
            "Layer: fc3.weight\n",
            "Difference between model.weights and NN parameters: True\n",
            "Layer: fc3.bias\n",
            "Difference between model.weights and NN parameters: True\n",
            "Layer: fc1.weight\n",
            "Difference between model.weights and NN parameters after reset: True\n",
            "Layer: fc1.bias\n",
            "Difference between model.weights and NN parameters after reset: True\n",
            "Layer: fc2.weight\n",
            "Difference between model.weights and NN parameters after reset: True\n",
            "Layer: fc2.bias\n",
            "Difference between model.weights and NN parameters after reset: True\n",
            "Layer: fc3.weight\n",
            "Difference between model.weights and NN parameters after reset: True\n",
            "Layer: fc3.bias\n",
            "Difference between model.weights and NN parameters after reset: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Manage e manipulate the weights of neural network using NNModel.\n",
        "#Make changes to the weights (simulating a \"move\" in a search or optimization process).\n",
        "#Revert changes to the weights if needed (like rejecting a move).\n",
        "# Inizializza la rete e il wrapper\n",
        "net = FeedforwardNet()\n",
        "nn_model = NNModel(net)\n",
        "\n",
        "# Salvataggio dei pesi iniziali\n",
        "w_initial = nn_model.copy()\n",
        "\n",
        "# Stampa dei pesi iniziali del layer fc1\n",
        "print(\"Pesi iniziali di fc1.weight:\")\n",
        "print(nn_model.weights['fc1.weight'])\n",
        "\n",
        "# Simulazione di una mossa, modifica del peso fc1.weight\n",
        "wnew = nn_model.copy()\n",
        "wnew['fc1.weight'] = wnew['fc1.weight'] + 1.0\n",
        "\n",
        "# Applica la mossa proposta\n",
        "nn_model.set_weights(wnew)\n",
        "print(\"\\nPesi dopo la mossa proposta di fc1.weight:\")\n",
        "print(nn_model.weights['fc1.weight'])\n",
        "\n",
        "# Supponiamo di voler rifiutare la mossa: ripristino della configurazione precedente\n",
        "nn_model.set_weights(w_initial)\n",
        "print(\"\\nPesi dopo il ripristino (rifiuto della mossa) di fc1.weight:\")\n",
        "print(nn_model.weights['fc1.weight'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCGscY6eWIx0",
        "outputId": "9a71a67b-acef-4223-f2e8-eda87a9c23f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pesi iniziali di fc1.weight:\n",
            "Parameter containing:\n",
            "tensor([[ 0.0961, -0.0802,  0.0636,  ...,  0.0916, -0.0843, -0.0768],\n",
            "        [ 0.0774,  0.0070,  0.0699,  ...,  0.0918, -0.0963, -0.0100],\n",
            "        [-0.0607,  0.0815,  0.0096,  ...,  0.0590,  0.0252,  0.0582],\n",
            "        ...,\n",
            "        [-0.0222,  0.0812, -0.0688,  ...,  0.0828,  0.0650, -0.0279],\n",
            "        [-0.0128,  0.0341,  0.0301,  ..., -0.0096, -0.0427, -0.0035],\n",
            "        [-0.0952,  0.0218,  0.0412,  ..., -0.0221,  0.1000,  0.0964]],\n",
            "       requires_grad=True)\n",
            "\n",
            "Pesi dopo la mossa proposta di fc1.weight:\n",
            "Parameter containing:\n",
            "tensor([[1.0961, 0.9198, 1.0636,  ..., 1.0916, 0.9157, 0.9232],\n",
            "        [1.0774, 1.0070, 1.0699,  ..., 1.0918, 0.9037, 0.9900],\n",
            "        [0.9393, 1.0815, 1.0096,  ..., 1.0590, 1.0252, 1.0582],\n",
            "        ...,\n",
            "        [0.9778, 1.0812, 0.9312,  ..., 1.0828, 1.0650, 0.9721],\n",
            "        [0.9872, 1.0341, 1.0301,  ..., 0.9904, 0.9573, 0.9965],\n",
            "        [0.9048, 1.0218, 1.0412,  ..., 0.9779, 1.1000, 1.0964]],\n",
            "       requires_grad=True)\n",
            "\n",
            "Pesi dopo il ripristino (rifiuto della mossa) di fc1.weight:\n",
            "Parameter containing:\n",
            "tensor([[ 0.0961, -0.0802,  0.0636,  ...,  0.0916, -0.0843, -0.0768],\n",
            "        [ 0.0774,  0.0070,  0.0699,  ...,  0.0918, -0.0963, -0.0100],\n",
            "        [-0.0607,  0.0815,  0.0096,  ...,  0.0590,  0.0252,  0.0582],\n",
            "        ...,\n",
            "        [-0.0222,  0.0812, -0.0688,  ...,  0.0828,  0.0650, -0.0279],\n",
            "        [-0.0128,  0.0341,  0.0301,  ..., -0.0096, -0.0427, -0.0035],\n",
            "        [-0.0952,  0.0218,  0.0412,  ..., -0.0221,  0.1000,  0.0964]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset\n",
        "Il dataset generato è costituito da vettori di spin ±1 di dimensione 100, con 10 diverse configurazioni iniziali.\n",
        "Ogni vettore subisce una perturbazione applicando una probabilità di flip del 10%, invertendo casualmente alcuni spin per introdurre rumore.\n",
        "L’output associato è una label one-hot, ovvero un vettore di 10 elementi con un unico valore pari a 1, che identifica quale vettore originale è stato usato come base per il campione modificato.\n",
        "Questa rappresentazione suggerisce un problema di classificazione in cui la rete neurale deve riconoscere la configurazione iniziale da cui proviene ogni input perturbato."
      ],
      "metadata": {
        "id": "cZEgv4Tl-IMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "def flip_spin(vector, p=0.1):\n",
        "    \"\"\"\n",
        "    Data una sequenza di spin (±1), inverte ciascun elemento con probabilità p.\n",
        "    \"\"\"\n",
        "    flip_mask = np.random.rand(vector.shape[0]) < p  # Quali spin invertire\n",
        "    vector_flipped = vector.copy()\n",
        "    vector_flipped[flip_mask] *= -1  # Inversione degli spin selezionati\n",
        "    return vector_flipped\n",
        "\n",
        "def generate_dataset(n_vectors=10, vector_dim=100, p_flip=0.1):\n",
        "    \"\"\"\n",
        "    Genera un dataset di n_vectors vettori, ognuno di 10dimensionale\n",
        "    Ogni vettore contiene spin ±1, e viene flippato con probabilità p_flip.\n",
        "    \"\"\"\n",
        "    dataset = []\n",
        "    labels = []\n",
        "\n",
        "    for k in range(n_vectors):\n",
        "        s_k = np.random.choice([-1, 1], size=vector_dim)  # Vettore iniziale\n",
        "        s_i = flip_spin(s_k, p_flip)  # Flippo\n",
        "        dataset.append(s_i)\n",
        "\n",
        "        # Creazione della label one-hot (10 classi)\n",
        "        label = np.zeros(n_vectors)\n",
        "        label[k] = 1\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(dataset), np.array(labels)\n",
        "\n",
        "class SpinDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset compatibile con PyTorch, restituisce coppie (input, target).\n",
        "    \"\"\"\n",
        "    def __init__(self, n_vectors=10, vector_dim=100, p_flip=0.1):\n",
        "        X, y = generate_dataset(n_vectors, vector_dim, p_flip)\n",
        "        self.X = torch.tensor(X, dtype=torch.float64)  # Input\n",
        "        self.y = torch.tensor(y, dtype=torch.float64)  # One-hot label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# Test dataset\n",
        "if __name__ == \"__main__\":\n",
        "    dataset = SpinDataset(n_vectors=10, vector_dim=100, p_flip=0.1)\n",
        "    print(\"Esempio di input:\", dataset[0][0])  # Un vettore di spin\n",
        "    print(\"Esempio di label:\", dataset[3][1])  # La label one-hot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3C8jX8sYiJz",
        "outputId": "6b0ab2d7-5096-42a8-b02c-d54f28f38431"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Esempio di input: tensor([ 1.,  1., -1., -1.,  1., -1., -1., -1.,  1., -1., -1., -1.,  1.,  1.,\n",
            "        -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
            "         1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,\n",
            "         1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1., -1.,  1., -1.,  1.,\n",
            "        -1.,  1., -1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
            "         1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1., -1.,  1., -1., -1., -1.,\n",
            "         1.,  1., -1., -1., -1.,  1., -1.,  1., -1.,  1., -1., -1., -1., -1.,\n",
            "        -1., -1.])\n",
            "Esempio di label: tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# training with ADAM"
      ],
      "metadata": {
        "id": "geQk0j_X-LXI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# training with SGD\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FeYlKNl9-PJ8"
      }
    }
  ]
}